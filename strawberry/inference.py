# -*- coding: utf-8 -*-
"""
ë”¸ê¸° ìƒìœ¡ ë‹¨ê³„ ë¶„ë¥˜ - ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
ì›ë³¸ Colab ì½”ë“œ ì„¹ì…˜ 8, 9 ê·¸ëŒ€ë¡œ
"""

import os, glob, re, time, warnings
import numpy as np
import pandas as pd
from tqdm import tqdm
from PIL import Image

import torch
import torchvision.transforms as T
from torchvision.transforms import InterpolationMode
import timm

warnings.filterwarnings("ignore")
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# =========================
# ê²½ë¡œ ì„¤ì • (VSCodeìš©)
# =========================
PUBLIC_DIR = "/root/sehyun/test/public"
SAMPLE_CSV = "/root/sehyun/sample_submission.csv"
MODEL_PATH = "/root/sehyun/model.pth"
ENSEMBLE_PATH = "/root/sehyun/ensemble_models.pth"
RUN_STAMP = time.strftime("%Y%m%d_%H%M%S")
DEST_ROOT = f"/root/sehyun/strawberry_cls_run_{RUN_STAMP}"  # ì¶œë ¥ í´ë”

IMG_SIZE = 384

# =========================
# ëª¨ë¸ ë¡œë“œ
# =========================
print("ëª¨ë¸ ë¡œë“œ ì¤‘...")
# ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ
checkpoint = torch.load(ENSEMBLE_PATH, map_location=DEVICE)
trained = []
CLASSES = checkpoint['classes']
id2name = checkpoint['id2name']
submit_id_map = checkpoint['submit_id_map']

for model_info in checkpoint['models']:
    model_name = model_info['model_name']
    
    try:
        model = timm.create_model(
            model_name,
            pretrained=False,
            num_classes=len(CLASSES),
            img_size=IMG_SIZE,
        ).to(DEVICE)
    except TypeError:
        model = timm.create_model(
            model_name,
            pretrained=False,
            num_classes=len(CLASSES),
        ).to(DEVICE)
    
    model.load_state_dict(model_info['model_state_dict'])
    model.eval()
    trained.append(('', model, model_info['accuracy']))  # nameì€ í•„ìš”ì—†ì–´ì„œ ë¹ˆ ë¬¸ìì—´
    print(f"âœ… ëª¨ë¸ ë¡œë“œ: {model_name} (Acc: {model_info['accuracy']:.4f})")

# =========================
# ì›ë³¸ ì½”ë“œ ì„¹ì…˜ 8 ê·¸ëŒ€ë¡œ
# =========================
val_tfms = T.Compose([
    T.Resize(int(IMG_SIZE*1.15), interpolation=InterpolationMode.BICUBIC),
    T.CenterCrop(IMG_SIZE),
    T.ToTensor(),
    T.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225)),
])

def image_paths_recursive(d):
    exts=(".jpg",".jpeg",".png",".bmp",".webp")
    ps=[]
    for e in exts: ps+=glob.glob(os.path.join(d,"**",f"*{e}"), recursive=True)
    return sorted(ps)

def extract_photo_no(fname):
    nums = re.findall(r"\d+", os.path.basename(fname))
    return int(max(nums, key=len)) if nums else None

if os.path.isdir(PUBLIC_DIR):
    public_imgs = image_paths_recursive(PUBLIC_DIR)
else:
    public_imgs = []

if len(public_imgs)==0:
    print(f"â„¹ï¸ PUBLIC í´ë”ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŒ: {PUBLIC_DIR}")
else:
    rows=[]; tfm = val_tfms
    with torch.no_grad():
        for pth in tqdm(public_imgs, desc="Public Inference"):
            img = Image.open(pth).convert("RGB")
            x = tfm(img).unsqueeze(0).to(DEVICE)
            probs=[]
            for _, mdl, _ in trained[:2]:
                probs.append(torch.softmax(mdl(x), dim=1).cpu().numpy()[0])
            pavg = np.mean(probs, axis=0)
            pred = int(np.argmax(pavg)); conf=float(pavg[pred])
            rows.append({
                "filename": os.path.basename(pth),
                "label": CLASSES[pred].split('_',1)[1] if '_' in CLASSES[pred] else CLASSES[pred]
            })
    pub_df = pd.DataFrame(rows).sort_values(["A","filename"], na_position="last")
    
    os.makedirs(DEST_ROOT, exist_ok=True)
    pub_csv = f"{DEST_ROOT}/public_predictions_all_ENS_{RUN_STAMP}.csv"
    pub_df.to_csv(pub_csv, index=False, encoding="utf-8-sig")
    print("Saved:", pub_csv)

# =========================
# ì›ë³¸ ì½”ë“œ ì„¹ì…˜ 9 ê·¸ëŒ€ë¡œ
# =========================
# ğŸ”§ ì—¬ê¸°ë¥¼ ë„ˆì˜ ìƒ˜í”Œ ì œì¶œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½!
SAMPLE_CSV = "/root/sehyun/sample_submission.csv"

assert len(trained) > 0, "ë¨¼ì € 7)ì—ì„œ ëª¨ë¸ì„ í•™ìŠµí•´ trainedë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”."
top_models = [mdl for _, mdl, _ in trained[:2]]  # ìƒìœ„ 2ê°œ ì•™ìƒë¸” ì‚¬ìš©

# -- ìœ í‹¸: ì´ë¯¸ì§€ 1ì¥ ì˜ˆì¸¡
def predict_one_image(img_path, tfm=val_tfms, models=top_models):
    with torch.no_grad():
        img = Image.open(img_path).convert("RGB")
        x = tfm(img).unsqueeze(0).to(DEVICE)
        probs = []
        for mdl in models:
            mdl.eval()
            probs.append(torch.softmax(mdl(x), dim=1).cpu().numpy()[0])
        pavg = np.mean(probs, axis=0)
        pred_id = int(np.argmax(pavg))
        pred_label = CLASSES[pred_id].split("_", 1)[1] if "_" in CLASSES[pred_id] else CLASSES[pred_id]
        conf = float(pavg[pred_id])
    return pred_id, pred_label, conf

# -- PUBLIC í´ë”ì—ì„œ íŒŒì¼ ë§¤ì¹­ ë„ìš°ë¯¸
def find_public_image_by_filename(filename):
    cand = glob.glob(os.path.join(PUBLIC_DIR, "**", filename), recursive=True)
    return cand[0] if len(cand) > 0 else None

def find_public_image_by_A(a_value):
    exts = (".jpg", ".jpeg", ".png", ".bmp", ".webp")
    patterns = [f"*{a_value}*{ext}" for ext in exts]
    cands = []
    for pat in patterns:
        cands += glob.glob(os.path.join(PUBLIC_DIR, "**", pat), recursive=True)
    for p in sorted(cands):
        if extract_photo_no(p) == a_value:
            return p
    return None

# -- sample_submission ì½ê¸°
sample = pd.read_csv(SAMPLE_CSV)
print("ğŸ” sample_submission columns:", list(sample.columns))

# ì–´ë–¤ ì»¬ëŸ¼ì— ì˜ˆì¸¡ì„ ì¨ì•¼ í•˜ëŠ”ì§€ ìë™ íŒë‹¨: label/target/pred ìˆœì„œ
submit_col = None
for cand in ["label", "target", "pred", "prediction", "y"]:
    if cand in sample.columns:
        submit_col = cand
        break
if submit_col is None:
    submit_col = "label"
    sample[submit_col] = ""

# ë§¤ì¹­ í‚¤ íŒë‹¨: filename ë˜ëŠ” A(ìˆ«ì)
has_filename = "filename" in sample.columns
has_A = "A" in sample.columns
if not has_filename and not has_A:
    raise ValueError("sample_submissionì— 'filename' ë˜ëŠ” 'A' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

pred_rows = []
missing = 0

print("ğŸ§  PUBLIC ì˜ˆì¸¡ìœ¼ë¡œ sample ì±„ìš°ëŠ” ì¤‘...")
for idx, row in tqdm(sample.iterrows(), total=len(sample)):
    img_path = None

    # 1) filename ìš°ì„  ë§¤ì¹­
    if has_filename and pd.notna(row.get("filename", None)):
        img_path = find_public_image_by_filename(str(row["filename"]).strip())

    # 2) ì‹¤íŒ¨ ì‹œ Aë¡œ ë§¤ì¹­
    if img_path is None and has_A and pd.notna(row.get("A", None)):
        try:
            a_val = int(row["A"])
            img_path = find_public_image_by_A(a_val)
        except:
            img_path = None

    if img_path is None:
        missing += 1
        pred_rows.append((idx, None, None, None))
        continue

    pred_id, pred_label, conf = predict_one_image(img_path, tfm=val_tfms, models=top_models)
    pred_rows.append((idx, pred_id, pred_label, conf))

# ğŸ”¢ sample ì±„ìš°ê¸° â€” "ìˆ«ì ë¼ë²¨(1~5)"ë¡œ ì €ì¥
for idx, pid, plabel, conf in pred_rows:
    if pid is None:
        continue
    submit_id = submit_id_map.get(plabel, None)
    if submit_id is None:
        klabel = str(plabel).split('_')[-1]
        submit_id = submit_id_map.get(klabel, pid+1)  # ìµœí›„ìˆ˜ë‹¨
    sample.at[idx, submit_col] = int(submit_id)

# ì €ì¥
SUBMIT_PATH = f"/root/sehyun/submission.csv"  # VSCode ê²½ë¡œë¡œ ìˆ˜ì •
os.makedirs(os.path.dirname(SUBMIT_PATH), exist_ok=True)
sample.to_csv(SUBMIT_PATH, index=False, encoding="utf-8-sig")

print(f"\nâœ… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {SUBMIT_PATH}")
print(f"   - ì±„ìš°ì§€ ëª»í•œ í–‰ ìˆ˜(missing): {missing}")
print(f"   - ì œì¶œ ì»¬ëŸ¼ëª…: {submit_col}")
print("   - ì œì¶œ ê°’ ì˜ˆì‹œ:", sample[submit_col].head().tolist())